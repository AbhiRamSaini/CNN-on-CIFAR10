{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "247181c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhir\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "378c141e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform= transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "130e2993",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,32,3)\n",
    "        self.conv2 = nn.Conv2d(32,32,3)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv3 = nn.Conv2d(32,64,3)\n",
    "        self.conv4 = nn.Conv2d(64,64,3, padding= 1)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(64*1*1,512)\n",
    "        self.fc2 = nn.Linear(512,128)\n",
    "        self.fc3 = nn.Linear(128,10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool2(F.relu(self.conv3(x)))\n",
    "        x = self.pool2(F.relu(self.conv4(x)))\n",
    "         \n",
    "        #print(x.size(1), x.size(2), x.size(3))\n",
    "        x = x.view(-1,64*1*1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "ner = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "07b7f65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(ner.parameters(), lr=0.01, momentum=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f3931890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40], Step [782/782], Loss: 1.0643, Accuracy: 0.5625\n",
      "Epoch [2/40], Step [782/782], Loss: 1.1893, Accuracy: 0.6875\n",
      "Epoch [3/40], Step [782/782], Loss: 0.9280, Accuracy: 0.6250\n",
      "Epoch [4/40], Step [782/782], Loss: 0.8646, Accuracy: 0.7500\n",
      "Epoch [5/40], Step [782/782], Loss: 0.8032, Accuracy: 0.7500\n",
      "Epoch [6/40], Step [782/782], Loss: 0.6382, Accuracy: 0.8750\n",
      "Epoch [7/40], Step [782/782], Loss: 1.0699, Accuracy: 0.6875\n",
      "Epoch [8/40], Step [782/782], Loss: 0.7000, Accuracy: 0.7500\n",
      "Epoch [9/40], Step [782/782], Loss: 0.4810, Accuracy: 0.8125\n",
      "Epoch [10/40], Step [782/782], Loss: 1.0660, Accuracy: 0.6250\n",
      "Epoch [11/40], Step [782/782], Loss: 0.7302, Accuracy: 0.7500\n",
      "Epoch [12/40], Step [782/782], Loss: 0.5530, Accuracy: 0.7500\n",
      "Epoch [13/40], Step [782/782], Loss: 0.6490, Accuracy: 0.8125\n",
      "Epoch [14/40], Step [782/782], Loss: 0.5633, Accuracy: 0.7500\n",
      "Epoch [15/40], Step [782/782], Loss: 0.8116, Accuracy: 0.6875\n",
      "Epoch [16/40], Step [782/782], Loss: 0.7055, Accuracy: 0.6250\n",
      "Epoch [17/40], Step [782/782], Loss: 0.3314, Accuracy: 0.8750\n",
      "Epoch [18/40], Step [782/782], Loss: 0.3112, Accuracy: 0.8750\n",
      "Epoch [19/40], Step [782/782], Loss: 0.5438, Accuracy: 0.7500\n",
      "Epoch [20/40], Step [782/782], Loss: 0.2375, Accuracy: 0.9375\n",
      "Epoch [21/40], Step [782/782], Loss: 0.5710, Accuracy: 0.8125\n",
      "Epoch [22/40], Step [782/782], Loss: 0.7835, Accuracy: 0.7500\n",
      "Epoch [23/40], Step [782/782], Loss: 0.7805, Accuracy: 0.8750\n",
      "Epoch [24/40], Step [782/782], Loss: 0.9689, Accuracy: 0.6875\n",
      "Epoch [25/40], Step [782/782], Loss: 0.7932, Accuracy: 0.7500\n",
      "Epoch [26/40], Step [782/782], Loss: 0.1843, Accuracy: 0.9375\n",
      "Epoch [27/40], Step [782/782], Loss: 0.2385, Accuracy: 0.8750\n",
      "Epoch [28/40], Step [782/782], Loss: 0.2997, Accuracy: 0.9375\n",
      "Epoch [29/40], Step [782/782], Loss: 0.6036, Accuracy: 0.6875\n",
      "Epoch [30/40], Step [782/782], Loss: 0.5916, Accuracy: 0.8125\n",
      "Epoch [31/40], Step [782/782], Loss: 0.2978, Accuracy: 0.8750\n",
      "Epoch [32/40], Step [782/782], Loss: 0.3597, Accuracy: 0.8125\n",
      "Epoch [33/40], Step [782/782], Loss: 0.2235, Accuracy: 0.8750\n",
      "Epoch [34/40], Step [782/782], Loss: 0.3604, Accuracy: 0.8750\n",
      "Epoch [35/40], Step [782/782], Loss: 0.2654, Accuracy: 0.8750\n",
      "Epoch [36/40], Step [782/782], Loss: 0.1651, Accuracy: 0.9375\n",
      "Epoch [37/40], Step [782/782], Loss: 0.2698, Accuracy: 0.9375\n",
      "Epoch [38/40], Step [782/782], Loss: 0.1820, Accuracy: 0.9375\n",
      "Epoch [39/40], Step [782/782], Loss: 0.1456, Accuracy: 0.9375\n",
      "Epoch [40/40], Step [782/782], Loss: 0.3053, Accuracy: 0.9375\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "learning_rate = 0.001\n",
    "num_epochs = 40\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(data, target) in enumerate(trainloader):  # Iterate over training data in batches\n",
    "        # Forward pass\n",
    "        output = ner(data)\n",
    "        loss = criterion(output, target)\n",
    "        _,predicted = torch.max(output[:len(target)],1)\n",
    "        accuracy = (predicted == target).sum().item()/len(target)\n",
    "\n",
    "        # Backward pass and optimizer step\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(trainloader)}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "de15887b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 68.43%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in testloader:\n",
    "        outputs = ner(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a873fefc",
   "metadata": {},
   "source": [
    "# Using BatchNormalization\n",
    "Adding batch normalization layers in the neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e133c2",
   "metadata": {},
   "source": [
    "# Using dropout \n",
    "adding dropout layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78ace88",
   "metadata": {},
   "source": [
    "# using Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "17b22172",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Dropout,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,32,3)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32,32,3)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv3 = nn.Conv2d(32,64,3)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64,64,3, padding= 1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(64*1*1,512)\n",
    "        self.fc2 = nn.Linear(512,128)\n",
    "        self.fc3 = nn.Linear(128,10)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool2(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool2(F.relu(self.bn4(self.conv4(x))))\n",
    "         \n",
    "        #print(x.size(1), x.size(2), x.size(3))\n",
    "        x = x.view(-1,64*1*1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "drop = Dropout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bd30dc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate :  0.1\n",
      "Epoch [1/10], Step [782/782], Loss: 0.8926, Accuracy: 0.5000\n",
      "Epoch [2/10], Step [782/782], Loss: 0.8110, Accuracy: 0.7500\n",
      "Epoch [3/10], Step [782/782], Loss: 1.0699, Accuracy: 0.6250\n",
      "Epoch [4/10], Step [782/782], Loss: 1.0075, Accuracy: 0.6250\n",
      "Epoch [5/10], Step [782/782], Loss: 0.9673, Accuracy: 0.8125\n",
      "Epoch [6/10], Step [782/782], Loss: 0.8055, Accuracy: 0.7500\n",
      "Epoch [7/10], Step [782/782], Loss: 0.7628, Accuracy: 0.6875\n",
      "Epoch [8/10], Step [782/782], Loss: 0.4392, Accuracy: 0.8125\n",
      "Epoch [9/10], Step [782/782], Loss: 0.6588, Accuracy: 0.6875\n",
      "Epoch [10/10], Step [782/782], Loss: 1.2137, Accuracy: 0.7500\n",
      "Accuracy of the network on the 10000 test images: 73.29%\n",
      "Finished Training\n",
      "Learning Rate :  0.01\n",
      "Epoch [1/10], Step [782/782], Loss: 1.4348, Accuracy: 0.6875\n",
      "Epoch [2/10], Step [782/782], Loss: 0.6557, Accuracy: 0.8750\n",
      "Epoch [3/10], Step [782/782], Loss: 0.8736, Accuracy: 0.7500\n",
      "Epoch [4/10], Step [782/782], Loss: 0.5747, Accuracy: 0.8750\n",
      "Epoch [5/10], Step [782/782], Loss: 0.4836, Accuracy: 0.8125\n",
      "Epoch [6/10], Step [782/782], Loss: 0.5042, Accuracy: 0.8125\n",
      "Epoch [7/10], Step [782/782], Loss: 0.9685, Accuracy: 0.6250\n",
      "Epoch [8/10], Step [782/782], Loss: 0.5728, Accuracy: 0.8125\n",
      "Epoch [9/10], Step [782/782], Loss: 0.3571, Accuracy: 0.9375\n",
      "Epoch [10/10], Step [782/782], Loss: 0.0862, Accuracy: 1.0000\n",
      "Accuracy of the network on the 10000 test images: 74.41%\n",
      "Finished Training\n",
      "Learning Rate :  0.001\n",
      "Epoch [1/10], Step [782/782], Loss: 0.4725, Accuracy: 0.8750\n",
      "Epoch [2/10], Step [782/782], Loss: 0.9052, Accuracy: 0.6875\n",
      "Epoch [3/10], Step [782/782], Loss: 0.8449, Accuracy: 0.8750\n",
      "Epoch [4/10], Step [782/782], Loss: 0.4455, Accuracy: 0.8125\n",
      "Epoch [5/10], Step [782/782], Loss: 1.1833, Accuracy: 0.6250\n",
      "Epoch [6/10], Step [782/782], Loss: 0.4102, Accuracy: 0.9375\n",
      "Epoch [7/10], Step [782/782], Loss: 0.8229, Accuracy: 0.7500\n",
      "Epoch [8/10], Step [782/782], Loss: 0.9037, Accuracy: 0.6875\n",
      "Epoch [9/10], Step [782/782], Loss: 0.0844, Accuracy: 1.0000\n",
      "Epoch [10/10], Step [782/782], Loss: 0.3938, Accuracy: 0.7500\n",
      "Accuracy of the network on the 10000 test images: 72.78%\n",
      "Finished Training\n",
      "Best Accuracy :  1.0\n"
     ]
    }
   ],
   "source": [
    "l2_lambda = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(drop.parameters(), lr=0.01, momentum=0, weight_decay=l2_lambda)\n",
    "batch_size = 256\n",
    "lr = [0.1,0.01,0.001]\n",
    "num_epochs = 10\n",
    "best_accuracy = 0\n",
    "# Training loop\n",
    "for learning_rate in lr:\n",
    "    print(\"Learning Rate : \", learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i,(data, target) in enumerate(trainloader):  # Iterate over training data in batches\n",
    "            # Forward pass\n",
    "            output = drop(data)\n",
    "            loss = criterion(output, target)\n",
    "            _,predicted = torch.max(output[:len(target)],1)\n",
    "            accuracy = (predicted == target).sum().item()/len(target)\n",
    "\n",
    "            # Backward pass and optimizer step\n",
    "            optimizer.zero_grad()  # Reset gradients\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if best_accuracy < accuracy:\n",
    "                best_accuracy = accuracy\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(trainloader)}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}')\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in testloader:\n",
    "            outputs = drop(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')\n",
    "    print('Finished Training')\n",
    "print(\"Best Accuracy : \", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a0f0c9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 72.77%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in testloader:\n",
    "        outputs = drop(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dac4210",
   "metadata": {},
   "source": [
    "# Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc747b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "# Define ResNet18 architecture\n",
    "resnet18 = models.resnet18(pretrained=True)  # Load pre-trained ResNet18 architecture\n",
    "\n",
    "# Modify the last layer to have 10 outputs for CIFAR-10\n",
    "num_ftrs = resnet18.fc.in_features\n",
    "resnet18.fc = nn.Linear(num_ftrs, 10)  # Modify the last fully connected layer\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet18.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Train the network\n",
    "for epoch in range(10):  # Example: Train for 10 epochs\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = resnet18(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:  # Print every 200 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Evaluate the network\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = resnet18(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bad38fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
